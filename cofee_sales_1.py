# -*- coding: utf-8 -*-
"""cofee_sales_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pKaBUU3ZTnIHLRydlsrnWnDkD_4NxmSV
"""

pip install pandas scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/cofee_sales.csv')

print(f"Shape: {df.shape}")
df.head()

"""**Data Cleaning & Feature Engineering**"""

df.columns = df.columns.str.strip().str.lower()
df.rename(columns={'money': 'sales'}, inplace=True)

# Missing values
num_cols = ['sales']
cat_cols = ['cash_type', 'card', 'coffee_name']

df[num_cols] = df[num_cols].fillna(df[num_cols].median())
for c in cat_cols:
    df[c] = df[c].fillna(df[c].mode()[0])

# Feature engineering
df['date'] = pd.to_datetime(df['date'], errors='coerce')
df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')

df['year']     = df['date'].dt.year
df['month']    = df['date'].dt.to_period('M').astype(str)
df['dayofwk']  = df['date'].dt.day_name()
df['hour']     = df['datetime'].dt.hour

df.head()

"""**Exploratory Data Analysis**"""

plt.rcParams['figure.figsize'] = (10, 5)

# Monthly sales trend
import plotly.express as px
monthly = df.groupby('month')['sales'].sum().reset_index()
px.line(monthly, x='month', y='sales', title='Monthly Coffee-Machine Revenue')

"""**Top products**"""

top_prod = df.groupby('coffee_name')['sales'].sum().sort_values(ascending=False)
sns.barplot(y=top_prod.index, x=top_prod.values, palette='viridis')
plt.title('Revenue by Coffee Type'); plt.xlabel('Revenue'); plt.ylabel('')
plt.show()

"""**Hourly sales heatmap**"""

import seaborn as sns
import matplotlib.pyplot as plt

# Group and pivot for heatmap
hourly = (df.groupby(['dayofwk', 'hour'])['sales']
            .sum().reset_index()
            .pivot(index='dayofwk', columns='hour', values='sales')
            .reindex(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']))

# Plot heatmap
plt.figure(figsize=(12,6))
sns.heatmap(hourly, cmap='crest', annot=True, fmt=".0f")
plt.title('Sales Heatmap: Hour vs Day of Week')
plt.xlabel('Hour of Day')
plt.ylabel('Day of Week')
plt.show()

# Hourly Sales per Coffee Product
hourly_by_product = (
    df.groupby(['hour', 'coffee_name'])['sales']
    .sum()
    .reset_index()
    .pivot(index='hour', columns='coffee_name', values='sales')
    .fillna(0)
)

fig, axs = plt.subplots(2, 4, figsize=(20, 10))
axs = axs.flatten()

for i, column in enumerate(hourly_by_product.columns):
    axs[i].bar(hourly_by_product.index, hourly_by_product[column], color='teal')
    axs[i].set_title(f'{column}')
    axs[i].set_xlabel('Hour')
    axs[i].set_ylabel('Sales')

plt.tight_layout()
plt.show()

"""**Machine Learning Modeling**"""

# Encode categorical variables
ml_df = df[['sales', 'coffee_name', 'cash_type', 'hour', 'dayofweek']]
ml_df = pd.get_dummies(ml_df, columns=['coffee_name', 'cash_type', 'dayofweek'], drop_first=True)

# Define target and features
X = ml_df.drop(columns=['sales'])
y = ml_df['sales']

# Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(df.columns.tolist())

df['date'] = pd.to_datetime(df['date'], errors='coerce')
df['dayofweek'] = df['date'].dt.day_name()
print(df[['date', 'dayofweek']].head())

ml_df = df[['sales', 'coffee_name', 'cash_type', 'hour', 'dayofweek']]
ml_df = pd.get_dummies(ml_df, columns=['coffee_name', 'cash_type', 'dayofweek'], drop_first=True)

# Define X (features) and y (target)
X = ml_df.drop(columns=['sales'])
y = ml_df['sales']

# Train/test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Data ready for modeling!")

"""**Linear Regression Model**"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Initialize and train model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)


y_pred = lr_model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Model Performance:")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R² Score: {r2:.2f}")

"""**Visualize Predictions vs Actual Sales**"""

import matplotlib.pyplot as plt

plt.figure(figsize=(10,5))
plt.scatter(y_test, y_pred, alpha=0.5, color='teal')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.ylabel('Predicted Sales')
plt.title('Actual vs Predicted Sales')
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Feature Importance**"""

import pandas as pd
import seaborn as sns

# Coefficients from the linear regression model
coeff_df = pd.DataFrame({
    'Feature': X.columns,
    'Coefficient': lr_model.coef_
}).sort_values(by='Coefficient', key=abs, ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(x='Coefficient', y='Feature', data=coeff_df, palette='crest')
plt.title('Feature Impact on Sales (Linear Regression)')
plt.tight_layout()
plt.show()

"""**Random Forest Regressor**"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Initialize and train the Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)


rf_pred = rf_model.predict(X_test)

rf_mse = mean_squared_error(y_test, rf_pred)
rf_r2 = r2_score(y_test, rf_pred)

print("Random Forest Model Performance:")
print(f"Mean Squared Error (MSE): {rf_mse:.2f}")
print(f"R² Score: {rf_r2:.2f}")

"""**Plot Predictions vs Actual (Random Forest)**

"""

plt.figure(figsize=(10, 5))
plt.scatter(y_test, rf_pred, alpha=0.5, color='darkorange')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('Actual Sales')
plt.ylabel('Predicted Sales')
plt.title('Actual vs Predicted Sales (Random Forest)')
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Feature Importance from Random Forest**"""

import pandas as pd
import seaborn as sns

rf_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': rf_model.feature_importances_
}).sort_values(by='Importance', ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(x='Importance', y='Feature', data=rf_importance, palette='Blues_d')
plt.title('Feature Importance (Random Forest)')
plt.tight_layout()
plt.show()

# Combine actual and predicted into one DataFrame
results_df = pd.DataFrame({
    'Actual_Sales': y_test,
    'Predicted_Sales': rf_pred
}).reset_index(drop=True)

results_df.to_csv('coffee_sales_predictions.csv', index=False)

from google.colab import files
files.download('coffee_sales_predictions.csv')

X_test_copy = X_test.copy()
X_test_copy['Actual_Sales'] = y_test.values
X_test_copy['Predicted_Sales'] = rf_pred

X_test_copy.to_csv('full_predictions_with_features.csv', index=False)
files.download('full_predictions_with_features.csv')